\section{What is Learning?}
Learning is the process of acquiring new knowledge, skills, or behaviors through experience. This process transforms inputs---such as data, experiences, or information---into useful capabilities like expertise, new skills, or predictive models.

\subsection{Core Elements of Learning}
Every learning process involves these fundamental components:
\begin{enumerate}
    \item \textbf{Input}: Data, experiences, or information that enters the learning system
    \item \textbf{Processing}: The manipulation or transformation of that data according to learning rules
    \item \textbf{Output}: The result---new knowledge, skills, or predictive capabilities
    \item \textbf{Feedback}: Information about the effectiveness of learning outcomes
    \item \textbf{Memory}: The ability to retain and access learned information
\end{enumerate}

\subsection{Key Questions in Learning}
\begin{itemize}
    \item What are the essential inputs for the learning process?
    \item How do we measure the effectiveness and success of learning?
    \item What are the underlying mechanisms and processes by which learning occurs?
    \item How can we generalize from specific experiences to handle new situations?
\end{itemize}

\section{What is Reasoning?}
Reasoning is the ability to draw logical conclusions from known facts or learned knowledge. Unlike learning, reasoning relies on logical inference rather than large amounts of data.

\section{Types of Reasoning: Comprehensive Overview}
Understanding different types of reasoning is crucial for designing effective learning systems. Each type has distinct characteristics and applications in both biological and artificial intelligence systems.

\subsection{Inductive Reasoning}
\textbf{Definition:} Inductive reasoning extracts patterns from observed data to make predictions about future or unseen cases. This approach moves from specific observations to general conclusions, yielding probable rather than certain results.

\textbf{Key Characteristics:}
\begin{itemize}
    \item Most prevalent form of reasoning in the animal kingdom and primary mode in machine learning
    \item Forms the basis of most learned behaviors in animals
    \item Used extensively in deep learning and LLMs
    \item Enables generalization from limited examples to broader patterns
\end{itemize}

\subsection{Deductive Reasoning}
\textbf{Definition:} Deductive reasoning moves from general rules and premises to reach specific, guaranteed conclusions. It starts with a general rule and a specific case to reach a logical conclusion.

\textbf{Key Characteristics:}
\begin{itemize}
    \item Provides certainty when premises are true
    \item Animals generally lack this capability for abstract reasoning
    \item LLMs can only mimic this through pattern matching
    \item Forms the basis of formal logic and mathematical proof
\end{itemize}

\subsection{Abductive Reasoning (Inference to Best Explanation)}
\textbf{Definition:} Abductive reasoning starts with an observation and seeks to find the simplest and most likely explanation. It's the process of finding a hypothesis that, if true, would best explain the observation.

\section{Animal Learning}
\subsection{Example: Bait Shyness in Rats}
Rats demonstrate a fundamental learning principle through their feeding behavior:
\begin{itemize}
    \item They sample novel food cautiously
    \item If the food causes illness, they avoid it in the future
    \item Past experience directly informs future decisions
\end{itemize}
This natural learning process parallels challenges in machine learning.

\section{Human Learning: The Cognitive Approach}
Human learning is a complex and multifaceted process that has been studied extensively in psychology and neuroscience. It involves a combination of conscious and unconscious processes, leading to the acquisition of knowledge and skills that are both explicit (declarative) and implicit (procedural).

\subsection{Cognitive Stages of Development}
Jean Piaget's theory of cognitive development provides a classic framework for understanding how learning capabilities evolve from infancy to adulthood.
\begin{itemize}
    \item \textbf{Sensorimotor Stage (0-2 years)}: Learning occurs through sensory experiences and motor interactions with the environment. Object permanence is a key milestone.
    \item \textbf{Preoperational Stage (2-7 years)}: Children begin to think symbolically and use words and pictures to represent objects. Their thinking is egocentric.
    \item \textbf{Concrete Operational Stage (7-11 years)}: Children begin to think logically about concrete events. They grasp concepts like conservation.
    \item \textbf{Formal Operational Stage (12+ years)}: Abstract reasoning and hypothetical thinking emerge.
\end{itemize}
This staged progression suggests that the ability to learn and the types of learning that are possible change fundamentally over a lifetime, a concept that has parallels in the development of more sophisticated machine learning models.

\subsection{The Role of Memory}
Memory is central to learning. The Atkinson-Shiffrin model is a classic theory that proposes three stages of memory:
\begin{enumerate}
    \item \textbf{Sensory Memory:} A very brief buffer for sensory information.
    \item \textbf{Short-Term Memory (Working Memory):} Holds a small amount of information for a short duration. It is where conscious thought and processing occur. This is analogous to the memory (RAM) of a computer.
    \item \textbf{Long-Term Memory:} The vast, semi-permanent storage of knowledge and skills. This is analogous to a computer's hard drive.
\end{enumerate}
The process of moving information from short-term to long-term memory, known as encoding, is critical for learning. Retrieval is the process of accessing this stored information. In machine learning, the "memory" is stored in the model's parameters (weights).

\subsection{Learning Styles and Strategies}
Humans employ a variety of strategies to learn, which can be broadly categorized:
\begin{itemize}
    \item \textbf{Rote learning:} Memorization through repetition (e.g., flashcards). This is similar to overfitting in machine learning, where a model memorizes the training data.
    \item \textbf{Observational learning:} Learning by watching others.
    \item \textbf{Associative learning:} Connecting stimuli or events that occur together in the environment (classical and operant conditioning).
    \item \textbf{Cognitive learning:} Learning through understanding, reasoning, and problem-solving. This is the goal of more advanced AI systems.
\end{itemize}

\section{What is Machine Learning?}
Machine learning is a subfield of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. At its core, machine learning involves developing models that can identify patterns in data and make predictions or decisions based on those patterns.

\subsection{Parallel: Spam Email Filtering}
Consider how biological learning principles apply to spam detection:
\begin{itemize}
    \item \textbf{Naive approach}: Memorize all past spam emails
    \item \textbf{Problem}: Cannot classify previously unseen emails
    \item \textbf{Solution}: Extract generalizable patterns (like words, phrases, or sender patterns)
    \item \textbf{Key insight}: Both rats and spam filters must generalize from specific experiences to handle new, similar situations
\end{itemize}

\section{Types of Machine Learning}
There are three main categories of machine learning algorithms:

\subsection{Supervised Learning}
In supervised learning, the algorithm is trained on a labeled dataset, meaning that each data point is tagged with a correct output. The goal is to learn a mapping function that can predict the output for new, unseen data. Common supervised learning tasks include classification and regression.

\subsection{Unsupervised Learning}
Unsupervised learning deals with unlabeled data. The algorithm tries to learn the underlying structure of the data without any explicit guidance. Common tasks include clustering, dimensionality reduction, and density estimation.

\subsection{Reinforcement Learning}
Reinforcement learning is concerned with how an agent ought to take actions in an environment so as to maximize some notion of cumulative reward. The algorithm learns by trial and error, receiving feedback in the form of rewards or punishments.

\section{The Data and Observation Model}
In machine learning, we typically represent our data as a matrix. Let's denote the dataset as $\mathcal{D}$. A common convention is to represent the data as a design matrix, $X$.

\subsection{The Design Matrix}
The design matrix $X$ is an $m \times n$ matrix, where $m$ is the number of training examples (or observations) and $n$ is the number of features (or variables). Each row of the matrix represents a single data point, and each column represents a feature.

$$ 
 X = \begin{pmatrix}
 x_{11} & x_{12} & \dots & x_{1n} \\
x_{21} & x_{22} & \dots & x_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
x_{m1} & x_{m2} & \dots & x_{mn}
\end{pmatrix}
$$ 

Each row $i$ corresponds to a data point $\mathbf{x}_i^T$, which is a row vector of size $n$.

\section{Probabilistic Model of Learning}
A powerful way to think about machine learning is from a probabilistic perspective. We can think of the learning process as finding a model that best explains the data. This is often framed as finding the parameters $\theta$ of a model that maximize the likelihood of observing the data.

The likelihood function is given by:
$$ 
\mathcal{L}(\theta | X) = P(X | \theta) 
$$ 

The goal of learning is to find the parameters $\hat{\theta}$ that maximize this likelihood. This is known as Maximum Likelihood Estimation (MLE).
$$ 
\hat{\theta}_{MLE} = \arg\max_{\theta} P(X | \theta)
$$ 

\section{Inductive Bias in Machine Learning}
\subsection{What is Inductive Bias?}
\textbf{Definition:} Inductive bias refers to the set of assumptions that a learning algorithm makes to generalize from limited training data to unseen data.

\textbf{Why is it Critical?}
Inductive bias is essential because:
\begin{itemize}
    \item Machine learning models have limited training data
    \item Models must generalize from past observations to unseen cases
    \item Without appropriate bias, models may overfit (memorizing training data without learning generalizable patterns)
    \item All successful learning algorithms require appropriate assumptions about their domain
\end{itemize}

\subsection{Types of Inductive Biases}

\subsubsection{Preference for Simpler Models (Occam's Razor)}
\begin{itemize}
    \item \textbf{Assumption}: Simpler explanations are preferred over complex ones
    \item \textbf{Example}: Decision trees with fewer splits are preferred because they generalize better
    \item \textbf{In Deep Learning}: Regularization techniques (L1, L2) penalize complex models
\end{itemize}

\subsubsection{Smoothness Assumption}
\begin{itemize}
    \item \textbf{Assumption}: Data points that are close together should have similar outputs
    \item \textbf{Example}: In image classification, two similar images should belong to the same class
    \item \textbf{In ML}: K-Nearest Neighbors (KNN) assumes nearby data points have the same label
\end{itemize}

\subsection{Inductive Bias in Specific Architectures}
\subsubsection{Convolutional Neural Networks (CNNs)}
CNNs are designed for image processing and rely on key inductive biases:

\textbf{1. Locality Bias (Local Connectivity)}
\begin{itemize}
    \item \textbf{Assumption}: Nearby pixels are more relevant than distant pixels
    \item \textbf{Example}: In facial recognition, CNN detects eyes, nose, mouth before recognizing entire face
\end{itemize}

\textbf{2. Translation Invariance}
\begin{itemize}
    \item \textbf{Assumption}: An object should be recognized regardless of position
    \item \textbf{How it works}: CNNs use shared convolutional filters
    \item \textbf{Example}: Handwritten digit "3" recognized anywhere in the image
\end{itemize}

\subsubsection{Recurrent Neural Networks (RNNs \& LSTMs)}
RNNs are designed for sequential data and rely on:

\textbf{1. Temporal Dependency Bias}
\begin{itemize}
    \item \textbf{Assumption}: Recent information is more important than distant past
    \item \textbf{Example}: In "The cat sat on the mat", nearby words are more related
\end{itemize}

\subsubsection{Transformers (BERT, GPT)}

\textbf{1. Attention-Based Bias (Self-Attention)}
\begin{itemize}
    \item \textbf{Assumption}: Important words can be anywhere in a sentence
    \item \textbf{Example}: In "The dog chased the ball...which was blue", "which" refers to "ball"
\end{itemize}

\section{Mathematical Foundations of Learning}
\subsection{Learning as Optimization}
Machine learning can be viewed as an optimization problem where we seek to find the best parameters \(\theta\) that minimize a loss function \(L(\theta)\):
\[\theta^* = \arg\min_\theta L(\theta)\]

\subsubsection{Components of a Learning System}
\begin{enumerate}
    \item \textbf{Hypothesis Space} \(\mathcal{H}\): The set of all possible functions the model can represent
    \item \textbf{Loss Function} \(L(\theta)\): Measures how well the model performs on the training data
    \item \textbf{Optimization Algorithm}: Method to find \(\theta^*\) (e.g., gradient descent)
    \item \textbf{Regularization}: Techniques to prevent overfitting and improve generalization
\end{enumerate}

\subsubsection{The Bias-Variance Tradeoff}
The expected prediction error can be decomposed as:
\[\text{Error} = \text{Bias}^2 + \text{Variance} + \text{Irreducible Error}\]
where:
\begin{itemize}
    \item \textbf{Bias}: Error due to simplifying assumptions in the model
    \item \textbf{Variance}: Error due to sensitivity to small fluctuations in training data
    \item \textbf{Irreducible Error}: Inherent noise in the data
\end{itemize}

\subsection{PAC Learning Framework}
\textbf{Probably Approximately Correct (PAC)} learning provides theoretical foundations for when learning is possible.

A concept class \(\mathcal{C}\) is PAC-learnable if there exists an algorithm that, for any distribution \(\mathcal{D}\) and any \(\epsilon, \delta > 0\), can find a hypothesis \(h\) such that:
\[\Pr[\text{error}(h) \leq \epsilon] \geq 1 - \delta\]
using polynomially many samples and computational steps.

\section{Symbolic AI vs Machine Learning}
\subsection{What is Symbolic AI?}
Also known as \textbf{Good Old-Fashioned AI (GOFAI)}, it represents knowledge using symbols, rules, and logic. It uses explicitly programmed rules for reasoning.

\subsection{Symbolic AI vs Machine Learning Comparison}
\begin{table}[h!]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Feature} & \textbf{Symbolic AI} & \textbf{Machine Learning} \\
\hline
Knowledge Source & Rules \& logic & Data \& patterns \\
Interpretability & Highly explainable & Often a black box \\
Adaptability & Rigid (manual updates) & Can generalize from data \\
Data Requirements & Minimal & Requires large datasets \\
Best Use Cases & Theorem proving & NLP, computer vision \\
\hline
\end{tabular}
\caption{Comparison of Symbolic AI and Machine Learning.}
\end{table}